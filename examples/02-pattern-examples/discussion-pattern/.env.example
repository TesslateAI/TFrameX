# TFrameX Discussion Pattern - Environment Configuration

# ===== LLM Configuration =====
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_MODEL_NAME=gpt-3.5-turbo

# For local Ollama:
# OPENAI_API_BASE=http://localhost:11434/v1
# OPENAI_API_KEY=ollama
# OPENAI_MODEL_NAME=llama3

# ===== Application Settings =====
APP_NAME=Discussion Pattern TFrameX
LOG_LEVEL=INFO